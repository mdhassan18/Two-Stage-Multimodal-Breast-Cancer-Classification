# -*- coding: utf-8 -*-
"""Stage2_Multimodal_Diagnosis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Nr7_nlcIMrHgfAuZrMQe1z840lz0C63J
"""

import os
import torch
import torch.nn as nn
import pandas as pd
import timm

# CELL #1
from google.colab import drive
drive.mount('/content/drive')

# CELL #1.5
import os

# CELL #2
PROJECT_ROOT = "/content/drive/MyDrive/BreastCancer_AI_Project"
MODEL_DIR = f"{PROJECT_ROOT}/models/stage2"
os.makedirs(MODEL_DIR, exist_ok=True)

# CELL #3
mammogram_encoder = timm.create_model(
    "efficientnet_b0", pretrained=True, num_classes=0
).cuda()

ultrasound_encoder = timm.create_model(
    "mobilenetv3_small_100", pretrained=True, num_classes=0
).cuda()

# CELL #4
class TextEncoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(2, 32),
            nn.ReLU(),
            nn.Linear(32, 64)
        )

    def forward(self, x):
        return self.net(x)

# CELL #5 (FIXED & ROBUST)

class LateFusionModel(nn.Module):
    def __init__(self, mam_dim, us_dim, txt_dim):
        super().__init__()
        self.text_encoder = TextEncoder()

        fused_dim = mam_dim + us_dim + txt_dim

        # Attention learns importance of each modality
        self.attention = nn.Linear(fused_dim, 3)

        # Final classifier
        self.classifier = nn.Linear(fused_dim, 2)

    def forward(self, mam, us, text):
        f_mam = mammogram_encoder(mam)
        f_us = ultrasound_encoder(us)
        f_txt = self.text_encoder(text)

        fused = torch.cat([f_mam, f_us, f_txt], dim=1)

        attn_weights = torch.softmax(self.attention(fused), dim=1)
        out = self.classifier(fused)

        return out, attn_weights

import torch

# CELL #6 (FIXED PROPERLY)
device = torch.device("cuda")

with torch.no_grad():
    dummy_img = torch.randn(1, 3, 224, 224).to(device)
    dummy_txt = torch.randn(1, 2).to(device)

    mam_dim = mammogram_encoder(dummy_img).shape[1]
    us_dim = ultrasound_encoder(dummy_img).shape[1]

    temp_text_encoder = TextEncoder().to(device)
    txt_dim = temp_text_encoder(dummy_txt).shape[1]

print("Feature dims:", mam_dim, us_dim, txt_dim)

model = LateFusionModel(mam_dim, us_dim, txt_dim).to(device)

# CELL #7 (TEMPORARY — DO NOT LOAD OLD WEIGHTS YET)

# model.load_state_dict(
#     torch.load(checkpoint_path, map_location=device)
# )

model.eval()
print("Model ready (fresh instance)")

# CELL #8
from PIL import Image
from torchvision import transforms

mam_transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor()
])

sample_mam_path = "/content/drive/MyDrive/BreastCancer_AI_Project/datasets/CBIS-DDSM/jpeg/1.3.6.1.4.1.9590.100.1.2.126082211045731020508108042042916052/1-240.jpg"

mam_img = Image.open(sample_mam_path).convert("RGB")
mam_tensor = mam_transform(mam_img).unsqueeze(0).to(device)

# CELL #9
us_transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor()
])

sample_us_path = "/content/drive/MyDrive/BreastCancer_AI_Project/datasets/BUSI/Dataset_BUSI_with_GT/benign/benign (1).png"

us_img = Image.open(sample_us_path).convert("RGB")
us_tensor = us_transform(us_img).unsqueeze(0).to(device)

# CELL #10
# Example: age=52, BIRADS=4
text_tensor = torch.tensor([[52, 4]], dtype=torch.float32).to(device)

# DEBUG CELL — DO NOT SKIP

with torch.no_grad():
    f_mam = mammogram_encoder(mam_tensor)
    f_us = ultrasound_encoder(us_tensor)
    f_txt = model.text_encoder(text_tensor)

print("Mammogram features:", f_mam.shape)
print("Ultrasound features:", f_us.shape)
print("Text features:", f_txt.shape)

# CELL #11 (UNCHANGED)

with torch.no_grad():
    outputs, attn_weights = model(mam_tensor, us_tensor, text_tensor)
    probs = torch.softmax(outputs, dim=1)

print("Probabilities:", probs.cpu().numpy())
print("Attention weights [Mam, US, Text]:", attn_weights.cpu().numpy())

# CELL #12
import pandas as pd
import random
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image

# CELL #13

cbis_csv = "/content/drive/MyDrive/BreastCancer_AI_Project/datasets/CBIS-DDSM/train_ready.csv"
busi_csv = "/content/drive/MyDrive/BreastCancer_AI_Project/datasets/BUSI/busi_train_ready.csv"

cbis_df = pd.read_csv(cbis_csv)
busi_df = pd.read_csv(busi_csv)

# BUSI: keep only benign & malignant
busi_df = busi_df[busi_df["label"].isin([1, 2])]

# Convert BUSI labels → 0 benign, 1 malignant
busi_df["label"] = busi_df["label"].map({1: 0, 2: 1})

print("CBIS:", cbis_df.shape)
print("BUSI:", busi_df.shape)

# CELL #14
img_tfms = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor()
])

# CELL #15

class MultimodalDataset(Dataset):
    def __init__(self, cbis_df, busi_df):
        self.cbis = cbis_df.reset_index(drop=True)
        self.busi = busi_df.reset_index(drop=True)

        # Split BUSI by label for fast sampling
        self.busi_by_label = {
            0: self.busi[self.busi.label == 0],
            1: self.busi[self.busi.label == 1]
        }

    def __len__(self):
        return len(self.cbis)

    def __getitem__(self, idx):
        # Mammogram
        mam_row = self.cbis.iloc[idx]
        mam_img = Image.open(
            "/content/drive/MyDrive/BreastCancer_AI_Project/datasets/CBIS-DDSM/" +
            mam_row.image_path
        ).convert("RGB")

        label = mam_row.label  # 0 benign, 1 malignant

        # Ultrasound (random same-label)
        us_row = self.busi_by_label[label].sample(1).iloc[0]
        us_img = Image.open(
            "/content/drive/MyDrive/BreastCancer_AI_Project/datasets/BUSI/" +
            us_row.image_path
        ).convert("RGB")

        # Transforms
        mam_img = img_tfms(mam_img)
        us_img = img_tfms(us_img)

        # Text (synthetic but realistic)
        age = random.randint(35, 75)
        birads = random.choice([3,4,5]) if label == 1 else random.choice([1,2,3])

        text = torch.tensor([age, birads], dtype=torch.float32)

        return mam_img, us_img, text, torch.tensor(label)

# CELL #16

dataset = MultimodalDataset(cbis_df, busi_df)

train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size

train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=8, shuffle=False)

print("Train batches:", len(train_loader))
print("Val batches:", len(val_loader))

# CELL #17
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# CELL #18

def train_epoch(loader):
    model.train()
    total_loss = 0

    for mam, us, text, label in loader:
        mam = mam.to(device)
        us = us.to(device)
        text = text.to(device)
        label = label.to(device)

        optimizer.zero_grad()
        outputs, _ = model(mam, us, text)
        loss = criterion(outputs, label)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    return total_loss / len(loader)

# CELL #19

def validate(loader):
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for mam, us, text, label in loader:
            mam = mam.to(device)
            us = us.to(device)
            text = text.to(device)
            label = label.to(device)

            outputs, _ = model(mam, us, text)
            preds = outputs.argmax(dim=1)

            correct += (preds == label).sum().item()
            total += label.size(0)

    return correct / total

# CELL #20

EPOCHS = 10

for epoch in range(EPOCHS):
    train_loss = train_epoch(train_loader)
    val_acc = validate(val_loader)

    print(f"Epoch {epoch+1}/{EPOCHS} | Loss: {train_loss:.4f} | Val Acc: {val_acc:.4f}")

# CELL #21

save_path = "/content/drive/MyDrive/BreastCancer_AI_Project/models/stage2/stage2_multimodal_final.pth"

torch.save(model.state_dict(), save_path)
print("✅ Stage-2 model saved to Drive")